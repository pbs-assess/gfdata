[{"path":"https://pbs-assess.github.io/gfdata/articles/01-gfdata-vignette.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Introduction to gfdata","text":"don’t already package installed, run: First load package along dplyr since use within code later.","code":"# install.packages(\"devtools\") devtools::install_github(\"pbs-assess/gfdata\") library(gfdata) library(dplyr)"},{"path":"https://pbs-assess.github.io/gfdata/articles/01-gfdata-vignette.html","id":"an-overview-of-gfdata","dir":"Articles","previous_headings":"","what":"An overview of gfdata","title":"Introduction to gfdata","text":"Commercial research catch, effort, biological data groundfish archived DFO Pacific Groundfish Data Unit (Fisheries Oceans Canada, Science Branch, Pacific Region) housed number relational databases archived -site Pacific Biological Station, Nanaimo, BC). gfdata package develeoped automate data extraction databases consistent, reproducible manner series get_*() functions. functions extract data using SQL queries, developed support Groundfish Data Unit. standardized datasets designed feed directly functions gfplot package, can course also analyzed outside gfplot. SQL code called get_*() functions can viewed :https://github.com/pbs-assess/gfata/tree/master/inst/sql various functions fit together:https://github.com/pbs-assess/gfplot/blob/master/inst/function-web.pdf Detailed information data extraction get_*() functions can found : Anderson, S.C., Keppel, E.., Edwards, .M.. “reproducible data synopsis 100 species British Columbia groundfish”. DFO Can. Sci. Advis. Sec. REs. Doc. 2019/nnn. iv + 327 p. complete list get_*() functions gfdata : get_*() functions extract data species, functions arguments additional filtering, survey series, management area, years, gear type, environmental data type. cases, get_*() functions can extract data one multiple species. functions can viewed available arguments help documentation set functions : addition, number get functions retain many relevant database columns users can filter , example, dplyr::filter(dat, x = \"y\").","code":"fns <- ls(\"package:gfdata\") sort(fns[grepl(\"get\", fns)]) #>  [1] \"get_active_survey_blocks\"    \"get_age_methods\"             \"get_age_precision\"           #>  [4] \"get_all_stomachs\"            \"get_all_survey_samples\"      \"get_all_survey_sets\"         #>  [7] \"get_catch\"                   \"get_catch_spatial\"           \"get_comm_gear_types\"         #> [10] \"get_commercial_hooks_per_fe\" \"get_commercial_samples\"      \"get_cpue_historical\"         #> [13] \"get_cpue_historical_hake\"    \"get_cpue_historical_hl\"      \"get_cpue_index\"              #> [16] \"get_cpue_index_hl\"           \"get_cpue_spatial\"            \"get_cpue_spatial_ll\"         #> [19] \"get_eulachon_specimens\"      \"get_fishery_ids\"             \"get_fishery_sectors\"         #> [22] \"get_gear_types\"              \"get_hake_catch\"              \"get_hake_survey_samples\"     #> [25] \"get_ll_hook_data\"            \"get_major_areas\"             \"get_management\"              #> [28] \"get_management_areas\"        \"get_other_surveys\"           \"get_parent_level_counts\"     #> [31] \"get_sable_landings\"          \"get_sablefish_surveys\"       \"get_sample_trips\"            #> [34] \"get_sensor_attributes\"       \"get_sensor_data_ll_ctd\"      \"get_sensor_data_ll_ctd_fe\"   #> [37] \"get_sensor_data_ll_td\"       \"get_sensor_data_ll_td_fe\"    \"get_sensor_data_trawl\"       #> [40] \"get_sensor_data_trawl_fe\"    \"get_skate_level_counts\"      \"get_species\"                 #> [43] \"get_species_groups\"          \"get_spp_sample_length_type\"  \"get_ssids\"                   #> [46] \"get_strata_areas\"            \"get_survey_blocks\"           \"get_survey_gear_types\"       #> [49] \"get_survey_ids\"              \"get_survey_index\"            \"get_survey_samples\"          #> [52] \"get_survey_sets\"             \"get_survey_stomachs\"         \"get_table\" ?get_data ?get_environmental_data ?get_lookup_tables"},{"path":"https://pbs-assess.github.io/gfdata/articles/01-gfdata-vignette.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Introduction to gfdata","text":"example, extract Pacific cod survey sample data following function call DFO laptop, appropriate database permissions, PBS network. Note duplicate records databases due relating record multiple stratification schemes alternative analyses. occurs, warning given. “Duplicate specimen IDs present overlapping survey stratifications. working data yourelf, filter selecting specific surveys. example, dat <- dat[!duplicated(dat$specimen_id), ]. tidying plotting functions within gfplot .” Either species name species code can given argument, species name, used, case-sensitive. following thing: extract multiple species , give list species argument: can restrict data extraction single trawl survey series including ssid (survey series id) argument. list survey series id codes, run lookup function get_ssids(). Select desired ssid include argument (.e. Queen Charlotte Sound bottom trawl survey):","code":"dat <- get_survey_samples(\"pacific cod\") #> All or majority of length measurements are Fork_Length #> Warning in get_survey_samples(\"pacific cod\"): Duplicate specimen IDs are present because of #> overlapping survey stratifications. If working with the data yourelf, filter them after selecting #> specific surveys. For example, `dat <- dat[!duplicated(dat$specimen_id), ]`. The tidying and #> plotting functions within gfplot will do this for you. head(dat) #> # A tibble: 6 x 40 #>   trip_start_date     fishing_event_id  year month  gear survey_series_id survey_abbrev #>   <dttm>                         <dbl> <int> <int> <dbl>            <dbl> <chr>         #> 1 2014-10-01 00:00:00          3420684  2014    10     5               76 DOG           #> 2 2019-10-01 00:00:00          5167333  2019    10     5               76 DOG           #> 3 2003-08-13 00:00:00           309491  2003     8     5               39 HBLL INS N    #> 4 2003-08-13 00:00:00           309493  2003     8     5               39 HBLL INS N    #> 5 2003-08-13 00:00:00           309503  2003     8     5               39 HBLL INS N    #> 6 2003-08-13 00:00:00           309506  2003     8     5               39 HBLL INS N    #> # i 33 more variables: survey_series_desc <chr>, survey_id <int>, major_stat_area_code <chr>, #> #   major_stat_area_name <chr>, minor_stat_area_code <chr>, species_code <chr>, #> #   species_common_name <chr>, species_science_name <chr>, specimen_id <dbl>, sample_id <dbl>, #> #   sex <dbl>, age_specimen_collected <int>, age <dbl>, sampling_desc <chr>, #> #   ageing_method_code <dbl>, length <dbl>, weight <int>, maturity_code <dbl>, maturity_name <chr>, #> #   maturity_desc <chr>, maturity_convention_code <dbl>, maturity_convention_desc <chr>, #> #   maturity_convention_maxvalue <dbl>, trip_sub_type_code <dbl>, sample_type_code <dbl>, ... get_survey_samples(\"pacific cod\") get_survey_samples(\"Pacific cod\") get_survey_samples(\"PaCiFiC cOD\") get_survey_samples(\"222\") get_survey_samples(222) get_survey_samples(c(\"pacific ocean perch\", \"pacific cod\")) get_survey_samples(c(396, 222)) get_survey_samples(c(222, \"pacific cod\")) ssids <- get_ssids() head(ssids) #> # A tibble: 6 x 3 #>   SURVEY_SERIES_ID SURVEY_SERIES_DESC                                 SURVEY_ABBREV #>              <dbl> <chr>                                              <chr>         #> 1                0 Individual survey without a series                 OTHER         #> 2                1 Queen Charlotte Sound Synoptic Bottom Trawl        SYN QCS       #> 3                2 Hecate Strait Multispecies Assemblage Bottom Trawl HS MSA        #> 4                3 Hecate Strait Synoptic Bottom Trawl                SYN HS        #> 5                4 West Coast Vancouver Island Synoptic Bottom Trawl  SYN WCVI      #> 6                5 Hecate Strait Pacific Cod Monitoring Bottom Trawl  OTHER dat <- get_survey_samples(222, ssid = 1) #> All or majority of length measurements are Fork_Length head(dat) #> # A tibble: 6 x 40 #>   trip_start_date     fishing_event_id  year month  gear survey_series_id survey_abbrev #>   <dttm>                         <dbl> <int> <int> <dbl>            <dbl> <chr>         #> 1 2003-07-03 00:00:00           308673  2003     7     1                1 SYN QCS       #> 2 2003-07-03 00:00:00           308673  2003     7     1                1 SYN QCS       #> 3 2003-07-03 00:00:00           308673  2003     7     1                1 SYN QCS       #> 4 2003-07-03 00:00:00           308673  2003     7     1                1 SYN QCS       #> 5 2003-07-03 00:00:00           308673  2003     7     1                1 SYN QCS       #> 6 2003-07-03 00:00:00           308673  2003     7     1                1 SYN QCS       #> # i 33 more variables: survey_series_desc <chr>, survey_id <int>, major_stat_area_code <chr>, #> #   major_stat_area_name <chr>, minor_stat_area_code <chr>, species_code <chr>, #> #   species_common_name <chr>, species_science_name <chr>, specimen_id <dbl>, sample_id <dbl>, #> #   sex <dbl>, age_specimen_collected <int>, age <dbl>, sampling_desc <chr>, #> #   ageing_method_code <dbl>, length <dbl>, weight <int>, maturity_code <dbl>, maturity_name <chr>, #> #   maturity_desc <chr>, maturity_convention_code <dbl>, maturity_convention_desc <chr>, #> #   maturity_convention_maxvalue <dbl>, trip_sub_type_code <dbl>, sample_type_code <dbl>, ... glimpse(dat) #> Rows: 11,509 #> Columns: 40 #> $ trip_start_date              <dttm> 2003-07-03, 2003-07-03, 2003-07-03, 2003-07-03, 2003-07-03, ~ #> $ fishing_event_id             <dbl> 308673, 308673, 308673, 308673, 308673, 308673, 308673, 30867~ #> $ year                         <int> 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2~ #> $ month                        <int> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7~ #> $ gear                         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ survey_series_id             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ survey_abbrev                <chr> \"SYN QCS\", \"SYN QCS\", \"SYN QCS\", \"SYN QCS\", \"SYN QCS\", \"SYN Q~ #> $ survey_series_desc           <chr> \"Queen Charlotte Sound Synoptic Bottom Trawl\", \"Queen Charlot~ #> $ survey_id                    <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ major_stat_area_code         <chr> \"05\", \"05\", \"05\", \"05\", \"05\", \"05\", \"05\", \"05\", \"05\", \"05\", \"~ #> $ major_stat_area_name         <chr> \"5A: SOUTHERN Q.C. SOUND\", \"5A: SOUTHERN Q.C. SOUND\", \"5A: SO~ #> $ minor_stat_area_code         <chr> \"11\", \"11\", \"11\", \"11\", \"11\", \"11\", \"11\", \"11\", \"11\", \"11\", \"~ #> $ species_code                 <chr> \"222\", \"222\", \"222\", \"222\", \"222\", \"222\", \"222\", \"222\", \"222\"~ #> $ species_common_name          <chr> \"pacific cod\", \"pacific cod\", \"pacific cod\", \"pacific cod\", \"~ #> $ species_science_name         <chr> \"gadus macrocephalus\", \"gadus macrocephalus\", \"gadus macrocep~ #> $ specimen_id                  <dbl> 7607986, 7607987, 7607988, 7607989, 7607990, 7607991, 7607992~ #> $ sample_id                    <dbl> 233551, 233551, 233551, 233551, 233551, 233551, 233551, 23355~ #> $ sex                          <dbl> 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2~ #> $ age_specimen_collected       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~ #> $ age                          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ sampling_desc                <chr> \"UNSORTED\", \"UNSORTED\", \"UNSORTED\", \"UNSORTED\", \"UNSORTED\", \"~ #> $ ageing_method_code           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ length                       <dbl> 21, 21, 23, 23, 23, 23, 23, 24, 24, 25, 26, 26, 27, 28, 28, 2~ #> $ weight                       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ maturity_code                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~ #> $ maturity_name                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ maturity_desc                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ maturity_convention_code     <dbl> 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9~ #> $ maturity_convention_desc     <chr> \"MATURITIES NOT LOOKED AT\", \"MATURITIES NOT LOOKED AT\", \"MATU~ #> $ maturity_convention_maxvalue <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~ #> $ trip_sub_type_code           <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3~ #> $ sample_type_code             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ species_category_code        <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ sample_source_code           <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ dna_sample_type              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ dna_container_id             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ usability_code               <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ grouping_code                <dbl> 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1~ #> $ length_type                  <chr> \"Fork_Length\", \"Fork_Length\", \"Fork_Length\", \"Fork_Length\", \"~ #> $ species_ageing_group         <chr> \"pcod_lingcod\", \"pcod_lingcod\", \"pcod_lingcod\", \"pcod_lingcod~"},{"path":"https://pbs-assess.github.io/gfdata/articles/01-gfdata-vignette.html","id":"caching-the-data-from-the-sql-servers","dir":"Articles","previous_headings":"","what":"Caching the data from the SQL servers","title":"Introduction to gfdata","text":"addition individual get_*() functions, function cache_pbs_data() runs get_*() functions caches data folder specify. useful able data available working later PBS network, saves running SQL queries (though data get updated occassionally --date data usually extracted analysis). helper function cache_pbs_data() extract data given species series .rds files whatever folder specify path argument. ’ll wrap quick check just make sure don’t download data twice build document . call list output files: call one object/dataframe (.e. survey sample data) list:","code":"cache_pbs_data(\"pacific cod\", path = \"pcod-cache\") #> Extracting data for #> Extracting survey samples #> All or majority of length measurements are Fork_Length #> Warning in get_survey_samples(this_sp): Duplicate specimen IDs are present because of overlapping #> survey stratifications. If working with the data yourelf, filter them after selecting specific #> surveys. For example, `dat <- dat[!duplicated(dat$specimen_id), ]`. The tidying and plotting #> functions within gfplot will do this for you. #> Extracting commercial samples #> All or majority of length measurements are Fork_Length #> Extracting catch #> Extracting spatial CPUE #> Extracting spatial LL CPUE #> Extracting spatial catch #> Extracting survey indexes #> Extracting aging precision #> All data extracted and saved in the folder `pcod-cache`. dat  <- readRDS(file.path(\"pcod-cache\", \"pacific-cod.rds\")) head(dat) #> $survey_samples #> # A tibble: 77,134 x 40 #>    trip_start_date     fishing_event_id  year month  gear survey_series_id survey_abbrev #>    <dttm>                         <dbl> <int> <int> <dbl>            <dbl> <chr>         #>  1 2014-10-01 00:00:00          3420684  2014    10     5               76 DOG           #>  2 2019-10-01 00:00:00          5167333  2019    10     5               76 DOG           #>  3 2003-08-13 00:00:00           309491  2003     8     5               39 HBLL INS N    #>  4 2003-08-13 00:00:00           309493  2003     8     5               39 HBLL INS N    #>  5 2003-08-13 00:00:00           309503  2003     8     5               39 HBLL INS N    #>  6 2003-08-13 00:00:00           309506  2003     8     5               39 HBLL INS N    #>  7 2003-08-13 00:00:00           309516  2003     8     5               39 HBLL INS N    #>  8 2003-08-13 00:00:00           309517  2003     8     5               39 HBLL INS N    #>  9 2003-08-13 00:00:00           309524  2003     8     5               39 HBLL INS N    #> 10 2003-08-13 00:00:00           309478  2003     8     5               39 HBLL INS N    #> # i 77,124 more rows #> # i 33 more variables: survey_series_desc <chr>, survey_id <int>, major_stat_area_code <chr>, #> #   major_stat_area_name <chr>, minor_stat_area_code <chr>, species_code <chr>, #> #   species_common_name <chr>, species_science_name <chr>, specimen_id <dbl>, sample_id <dbl>, #> #   sex <dbl>, age_specimen_collected <int>, age <dbl>, sampling_desc <chr>, #> #   ageing_method_code <dbl>, length <dbl>, weight <int>, maturity_code <dbl>, maturity_name <chr>, #> #   maturity_desc <chr>, maturity_convention_code <dbl>, maturity_convention_desc <chr>, ... #>  #> $commercial_samples #> # A tibble: 155,282 x 54 #>    trip_start_date     trip_end_date       trip_year  year month   day time_deployed #>    <dttm>              <dttm>                  <int> <dbl> <int> <int> <dttm>        #>  1 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #>  2 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #>  3 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #>  4 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #>  5 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #>  6 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #>  7 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #>  8 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #>  9 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #> 10 1962-04-19 00:00:00 1962-04-30 00:00:00      1962  1962     4     2 NA            #> # i 155,272 more rows #> # i 47 more variables: time_retrieved <dttm>, trip_id <dbl>, fishing_event_id <dbl>, #> #   latitude <dbl>, lat_start <dbl>, lat_end <dbl>, longitude <dbl>, lon_start <dbl>, #> #   lon_end <dbl>, best_depth <dbl>, gear_code <dbl>, gear_desc <chr>, species_code <chr>, #> #   species_common_name <chr>, species_science_name <chr>, sample_id <dbl>, specimen_id <dbl>, #> #   sex <dbl>, age_specimen_collected <int>, age <dbl>, ageing_method_code <dbl>, length <dbl>, #> #   weight <int>, maturity_code <dbl>, maturity_convention_code <dbl>, ... #>  #> $catch #> # A tibble: 333,430 x 27 #>    database_name trip_id  fishing_event_id fishery_sector   trip_category gear   best_date           #>    <chr>         <chr>    <chr>            <chr>            <chr>         <chr>  <dttm>              #>  1 GFCatch       54000002 1                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-04 00:00:00 #>  2 GFCatch       54000054 1                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-04 00:00:00 #>  3 GFCatch       54000001 1                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-04 00:00:00 #>  4 GFCatch       54000055 1                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-04 00:00:00 #>  5 GFCatch       54000034 1                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-05 00:00:00 #>  6 GFCatch       54000003 1                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-07 00:00:00 #>  7 GFCatch       54000036 4                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-07 00:00:00 #>  8 GFCatch       54000061 1                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-07 00:00:00 #>  9 GFCatch       54000036 3                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-07 00:00:00 #> 10 GFCatch       54000037 1                GROUNDFISH TRAWL <NA>          BOTTO~ 1954-01-07 00:00:00 #> # i 333,420 more rows #> # i 20 more variables: fe_start_date <dttm>, fe_end_date <dttm>, lat <dbl>, lon <dbl>, #> #   best_depth <int>, species_code <chr>, dfo_stat_area_code <chr>, dfo_stat_subarea_code <int>, #> #   species_scientific_name <chr>, species_common_name <chr>, landed_kg <dbl>, discarded_kg <dbl>, #> #   landed_pcs <int>, discarded_pcs <int>, major_stat_area_code <chr>, minor_stat_area_code <chr>, #> #   major_stat_area_name <chr>, vessel_name <chr>, vessel_registration_number <chr>, year <dbl> #>  #> $cpue_spatial #> # A tibble: 77,392 x 11 #>     year best_date           major_stat_area_code trip_id fishing_event_id   lat   lon #>    <int> <dttm>              <chr>                  <int>            <int> <dbl> <dbl> #>  1  2007 2007-05-08 09:50:00 06                     83395           732412  51.4 -129. #>  2  2007 2007-05-08 11:15:00 06                     83395           732415  51.4 -129. #>  3  2007 2007-05-07 16:30:00 06                     83395           732418  51.3 -129. #>  4  2007 2007-05-08 19:55:00 06                     83395           732419  51.3 -129. #>  5  2007 2007-05-07 09:30:00 07                     83739           736980  52.4 -130. #>  6  2007 2007-05-11 08:07:00 05                     83739           736990  50.8 -129. #>  7  2007 2007-05-08 17:26:00 08                     83916           726785  54.5 -131. #>  8  2007 2007-05-07 13:17:00 08                     83916           726787  54.5 -131. #>  9  2007 2007-05-08 11:14:00 08                     83916           726788  54.5 -131. #> 10  2007 2007-05-08 07:15:00 08                     83916           726790  54.5 -131. #> # i 77,382 more rows #> # i 4 more variables: vessel_registration_number <int>, species_scientific_name <chr>, #> #   species_common_name <chr>, cpue <dbl> #>  #> $cpue_spatial_ll #> # A tibble: 8,899 x 16 #>     year best_date           fishery_sector vessel_registration_num~1 gear  trip_id fishing_event_id #>    <int> <dttm>              <chr>                              <int> <chr>   <int>            <int> #>  1  2006 2006-03-12 12:00:00 halibut                            30850 long~   60792           512243 #>  2  2006 2006-03-06 09:30:00 halibut                            22452 long~   60809           512797 #>  3  2006 2006-03-07 10:10:00 halibut                            22452 long~   60809           512802 #>  4  2006 2006-03-07 12:00:00 halibut                            22452 long~   60809           512803 #>  5  2006 2006-03-09 20:00:00 halibut                            22452 long~   60809           512806 #>  6  2006 2006-03-10 10:45:00 halibut                            23703 long~   60944           511671 #>  7  2006 2006-03-11 14:45:00 halibut                            23703 long~   60944           511683 #>  8  2006 2006-03-12 09:15:00 halibut                            23703 long~   60944           511701 #>  9  2006 2006-03-12 17:00:00 halibut                            23703 long~   60944           511705 #> 10  2006 2006-03-13 23:59:00 halibut                            22452 long~   61099           513046 #> # i 8,889 more rows #> # i abbreviated name: 1: vessel_registration_number #> # i 9 more variables: lat <dbl>, lon <dbl>, species_code <chr>, species_scientific_name <chr>, #> #   species_common_name <chr>, landed_round_kg <dbl>, cpue <int>, total_released_pcs <int>, #> #   major_stat_area_code <chr> #>  #> $catch_spatial #> # A tibble: 77,392 x 11 #>     year best_date           major_stat_area_code trip_id fishing_event_id   lat   lon #>    <int> <dttm>              <chr>                  <int>            <int> <dbl> <dbl> #>  1  2007 2007-12-28 14:25:00 01                     99701           881231  48.9 -123. #>  2  2007 2007-12-28 16:23:00 01                     99701           881232  48.9 -123. #>  3  2007 2007-12-28 18:13:00 01                     99701           881233  48.9 -123. #>  4  2007 2007-12-28 20:10:00 01                     99701           881234  48.9 -123. #>  5  2007 2007-12-29 08:20:00 01                     99701           881235  48.9 -123. #>  6  2007 2007-12-29 10:01:00 01                     99701           881236  48.9 -123. #>  7  2007 2007-12-28 08:35:00 01                     99705           881398  49.3 -123. #>  8  2007 2007-12-29 15:01:00 01                     99705           881402  49.2 -123. #>  9  2007 2007-12-29 10:48:00 01                     99711           881395  49.3 -123. #> 10  2007 2007-04-05 17:50:00 01                     82028           880764  48.9 -123. #> # i 77,382 more rows #> # i 4 more variables: vessel_registration_number <int>, species_scientific_name <chr>, #> #   species_common_name <chr>, catch <dbl> dat <- dat$survey_samples head(dat) #> # A tibble: 6 x 40 #>   trip_start_date     fishing_event_id  year month  gear survey_series_id survey_abbrev #>   <dttm>                         <dbl> <int> <int> <dbl>            <dbl> <chr>         #> 1 2014-10-01 00:00:00          3420684  2014    10     5               76 DOG           #> 2 2019-10-01 00:00:00          5167333  2019    10     5               76 DOG           #> 3 2003-08-13 00:00:00           309491  2003     8     5               39 HBLL INS N    #> 4 2003-08-13 00:00:00           309493  2003     8     5               39 HBLL INS N    #> 5 2003-08-13 00:00:00           309503  2003     8     5               39 HBLL INS N    #> 6 2003-08-13 00:00:00           309506  2003     8     5               39 HBLL INS N    #> # i 33 more variables: survey_series_desc <chr>, survey_id <int>, major_stat_area_code <chr>, #> #   major_stat_area_name <chr>, minor_stat_area_code <chr>, species_code <chr>, #> #   species_common_name <chr>, species_science_name <chr>, specimen_id <dbl>, sample_id <dbl>, #> #   sex <dbl>, age_specimen_collected <int>, age <dbl>, sampling_desc <chr>, #> #   ageing_method_code <dbl>, length <dbl>, weight <int>, maturity_code <dbl>, maturity_name <chr>, #> #   maturity_desc <chr>, maturity_convention_code <dbl>, maturity_convention_desc <chr>, #> #   maturity_convention_maxvalue <dbl>, trip_sub_type_code <dbl>, sample_type_code <dbl>, ..."},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"why-use-a-get_all_-function","dir":"Articles","previous_headings":"","what":"Why use a get_all_*() function?","title":"Using 'get_all' functions","text":"original get_*() survey functions limited returning sets specimen samples conform current survey design specifications based assigned grouping usability codes. works well surveys data uses depend sampling consistent survey footprint across years generating design-based abundance indexes. uses can harness information samples collected outside current survey footprint different types surveys, don’t consistently apply codes. get_all_*() functions designed retrieve fishery-independent survey data relevant particular species, set species, quickly comprehensively original functions. retrieving data multiple species , functions dramatically faster original get_*() functions. sql scripts called species rather repeatedly species. retrieving data single species run times depend surveys arguments used. extent data returned can specific single survey, single major stat area, combination , generalized get everything database appropriately formatted.  Additional variables also returned support modelling objectives decisions regarding data retained specific purposes.","code":""},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"more-flexibility","dir":"Articles","previous_headings":"Why use a get_all_*() function?","what":"More flexibility","title":"Using 'get_all' functions","text":"original functions required user specify survey series ids (ssid) limited accept return.  get_all_*() functions, option set ssid = NULL return fishery-independent samples catch data database, long survey series ids (catch data, survey ids well) assigned database. include trap (sablefish), longline, jig, contemporary historic trawl surveys (exceptions include Nearshore Shrimp trawl survey survey ids missing). character string major stat area codes provided argument major, sets samples area returned.","code":""},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"design-based-analyses","dir":"Articles","previous_headings":"Why use a get_all_*() function?","what":"Design-based analyses","title":"Using 'get_all' functions","text":"original get_*() survey functions intended return sets specimen samples conform current survey design specifications, retrieve sets samples cells fall outside latest definition particular survey’s design. behaviour desired, can reproduced using get_all_*() functions filtering options usability = c(0, 1, 2, 6) grouping_only = TRUE. works reliably groundfish bottom trawl longline surveys (ssid = c(1, 2, 3, 4, 16, 22, 36, 39, 40)). However, filtering options applied certain surveys, small proportion data returned original function may missed (e.g., IPHC: ssid = 14) data returned surveys grouping usability codes appear database (e.g., jig survey: ssid = c(82:87)). using get_all_*() functions generate design-based indices, strata area variable now called grouping_area_km2 (instead area_km2 avoid confusion area_swept* variables) , case design changes occur incorporated usability codes, one also always check differences grouping_code grouping_code_updated variables. grouping_code_updated generally contains subset former, likely result shrinking footprint dropping entire strata survey’s definition. currently case offshore shrimp, also known multi-species small-mesh (MSSM), surveys (ssid = c(6, 7)), needs filtered sets updated grouping codes (!.na(grouping_code_updated)) order match current survey design. Consulting data stewards specific surveys may helpful understanding differences grouping codes. retrieve specimen samples conform design specifications, arguments unsorted_only = TRUE random_only = TRUE used addition usability grouping options. get_all_survey_samples() function return > 70 additional specimens original function longline surveys (ssid = c(22, 36, 39, 40)). original get_survey_samples() function used stricter method filtering based grouping codes. stricter filtering matches get_survey_sets() filtered current trawl survey footprint, filtered sets longline surveys. desired, stricter filtering can achieved sets samples survey filtering !.na(grouping_code_updated).","code":""},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"non-standard-data","dir":"Articles","previous_headings":"Why use a get_all_*() function?","what":"Non-standard data","title":"Using 'get_all' functions","text":"contrast, default behaviour get_all_*() survey functions return data collected given survey, whether conforms current design. includes sets samples grid cells within subsequently established Rockfish Conservation areas (RCAs), data differ skate level. original functions built retrieve data differed skate level, like gear comparison studies (e.g., ssid = 48). get_all_*() functions automatically return catch information skate level, instead fishing event level, sets within single function call whenever gear variables (currently checking differences hook code size) differ skates.","code":""},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"set-up","dir":"Articles","previous_headings":"","what":"Set up","title":"Using 'get_all' functions","text":"don’t already package installed, see general gfdata vignette instructions. load gfdata along package dplyr. available arguments described help documentation:","code":"library(gfdata) library(dplyr) library(tibble) ?get_all_survey_sets() ?get_all_survey_samples()"},{"path":[]},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"what-survey-data-is-available-for-a-species","dir":"Articles","previous_headings":"Examples","what":"What survey data is available for a species?","title":"Using 'get_all' functions","text":"example, might want determine survey set data database Bluntnose Sixgill Sharks (Hexanchus griseus). now, leave default settings pull surveys areas. Beware records database outside Canadian waters. desired, returned data can filtered using major_stat_area_code retain Canadian records (see get_major_areas() identify codes use).","code":""},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"original-get_survey_sets-function","dir":"Articles","previous_headings":"Examples > What survey data is available for a species?","what":"Original get_survey_sets() function","title":"Using 'get_all' functions","text":"start , check original get_survey_sets() function returns species. default function returns just commonly used groundfish surveys: synoptic trawl (ssid = c(1, 3, 4, 16)), one historical trawl (2), five longline–IPHC (14) PHMA (22, 36, 39, 40) surveys. first thing note function return one row per fishing event (unless overlapping survey series sample_ids requested). function also return sets survey series, even species never recorded survey. contrast, get_all_survey_sets() returns set data survey series captured species least . *_survey_sets() functions return sets survey series returned, including record species. , make sets capture species visible head(), sort descending catch_count. Notice catch_weight sometimes contains zeros catch_count least 1. original SQL code assume NULL values zeros. many cases catch weights missing collected type survey. However, even surveys weights usual unit measurement, particular catch may large small scale therefore recorded count. get_all_survey_sets(), default setting remove_false_zeros = TRUE, removes misleading zeros data.","code":"d0 <- get_survey_sets(\"Bluntnose Sixgill Shark\") nrow(d0) #> number of rows #> [1] 15349 length(unique(d0$fishing_event_id)) #> number of fishing events #> [1] 15349 sort(unique(d0$survey_series_id)) #> all default survey series were returned #>  [1]  1  2  3  4 14 16 22 36 39 40 d0 <- d0 |> rename(ssid = survey_series_id) |>   relocate(year, fishing_event_id, catch_count, catch_weight, ssid, survey_abbrev,            survey_series_desc) |>   arrange(-catch_count, -fishing_event_id) head(d0, n = 8L) #> # A tibble: 8 x 36 #>    year fishing_event_id catch_count catch_weight  ssid survey_abbrev survey_series_desc   survey_id #>   <int>            <dbl>       <dbl>        <dbl> <dbl> <chr>         <chr>                    <int> #> 1  2018          5092608          24            0    14 IPHC FISS     International Pacif~       538 #> 2  2018          5087665          14            0    14 IPHC FISS     International Pacif~       538 #> 3  2018          5093313          13            0    14 IPHC FISS     International Pacif~       538 #> 4  2018          5089779          10            0    14 IPHC FISS     International Pacif~       538 #> 5  2018          5074269          10            0    14 IPHC FISS     International Pacif~       538 #> 6  2018          5090481           9            0    14 IPHC FISS     International Pacif~       538 #> 7  2018          5074976           8            0    14 IPHC FISS     International Pacif~       538 #> 8  2018          5091185           6            0    14 IPHC FISS     International Pacif~       538 #> # i 28 more variables: species_code <chr>, survey_desc <chr>, trip_id <dbl>, #> #   fe_major_level_id <dbl>, latitude <dbl>, longitude <dbl>, grouping_code <dbl>, #> #   major_stat_area_code <chr>, minor_stat_area_code <chr>, depth_m <dbl>, duration_min <int>, #> #   doorspread_m <dbl>, speed_mpm <dbl>, tow_length_m <dbl>, density_kgpm2 <dbl>, #> #   density_pcpm2 <dbl>, skate_count <int>, hook_count <int>, density_ppkm2 <dbl>, month <int>, #> #   day <int>, time_deployed <dttm>, time_retrieved <dttm>, latitude_end <dbl>, #> #   longitude_end <dbl>, species_common_name <chr>, species_science_name <chr>, ..."},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"using-get_all_survey_sets","dir":"Articles","previous_headings":"Examples > What survey data is available for a species?","what":"Using get_all_survey_sets()","title":"Using 'get_all' functions","text":"Messages warnings alert user nuances data requested returned. example, function call results multiple rows data share fishing_event_id warning suggests possible reasons . case, number rows data exceeds number fishing events catch returned skate level fishing events. happen time skates within fishing event differ gear (currently just working differences hook type size). Now, view data catch_weight appears appropriately NA data collected. now also get catches skate level (multiple skates make fishing event) dogfish comparison work (ssid = c(48)) () returned get_survey_sets() due gear differences skates. , surveys encountered species? surveys count individuals others weigh total catch, summarize count weight variables. can also tally number unique fishing events versus number rows data returned see surveys returned skate level. case SSID 48. vast majority records Bluntnose Sixgill Shark come IPHC, followed Dogfish Hard Bottom Longline surveys, conducted Strait Georgia (aka. Inside South). IPHC covers wider area, can explore spatial distribution catches within survey , confirm frequently caught Strait Georgia, major stat area \"01\".","code":"d <- get_all_survey_sets(\"Bluntnose Sixgill Shark\") #> [1] \"Returning all sets/events/skates (including those with no catch) from all survey series that recorded Bluntnose Sixgill Shark at least once.\" #> Warning in get_all_survey_sets(\"Bluntnose Sixgill Shark\"): Duplicate fishing_event_ids are still #> present despite `remove_duplicates = TRUE`. This may be because of overlapping survey #> stratifications or multiple skates per event (specifically when at least one survey included used #> skates with differences in gear type), but could also be due to trips participating in more than #> one type of survey. If the latter, location, gear, or `reason_desc` columns should be used to #> choose which events to keep. After selecting specific survey stratifications and determining that #> all relevant variables are accurate, the remaining duplications can be filtered using `dat <- #> dat[!duplicated(dat$fishing_event_id), ]`. #> Warning in get_all_survey_sets(\"Bluntnose Sixgill Shark\"): All sablefish research related sets are #> returned as survey_series_id 35. To separate types of sets, use reason_desc and grouping_code #> variables. nrow(d) #> number of rows #> [1] 18967 length(unique(d$fishing_event_id)) #> number of fishing events #> [1] 18840 sort(unique(d$survey_series_id)) #> only returns survey series that caught the species #>  [1]  4  6  7 14 34 35 36 39 40 45 48 76 80 d <- d |> rename(ssid = survey_series_id) |>   relocate(year, fishing_event_id, catch_count, catch_weight, ssid, survey_abbrev,            activity_desc, skate_id) |>   arrange(-catch_count, -fishing_event_id) head(d, n = 8L) #> # A tibble: 8 x 75 #>    year fishing_event_id catch_count catch_weight  ssid survey_abbrev activity_desc         skate_id #>   <int>            <dbl>       <dbl>        <dbl> <dbl> <chr>         <chr>                    <dbl> #> 1  2018          5092608          24           NA    14 IPHC FISS     INTERNATIONAL PACIFI~       NA #> 2  2018          5087665          14           NA    14 IPHC FISS     INTERNATIONAL PACIFI~       NA #> 3  2018          5093313          13           NA    14 IPHC FISS     INTERNATIONAL PACIFI~       NA #> 4  2018          5089779          10           NA    14 IPHC FISS     INTERNATIONAL PACIFI~       NA #> 5  2018          5074269          10           NA    14 IPHC FISS     INTERNATIONAL PACIFI~       NA #> 6  2018          5090481           9           NA    14 IPHC FISS     INTERNATIONAL PACIFI~       NA #> 7  2018          5074976           8           NA    14 IPHC FISS     INTERNATIONAL PACIFI~       NA #> 8  2023          5795618           6           NA    48 OTHER         DOGFISH GEAR/TIMING ~  5788696 #> # i 67 more variables: species_common_name <chr>, species_code <chr>, fe_major_level_id <dbl>, #> #   trip_id <dbl>, survey_series_og <dbl>, survey_id <int>, activity_code <dbl>, reason_desc <chr>, #> #   trip_year <int>, month <int>, day <int>, time_deployed <dttm>, time_retrieved <dttm>, #> #   time_end_deployment <dttm>, time_begin_retrieval <dttm>, latitude <dbl>, longitude <dbl>, #> #   latitude_end <dbl>, longitude_end <dbl>, major_stat_area_code <chr>, #> #   minor_stat_area_code <chr>, depth_m <dbl>, depth_begin <dbl>, depth_end <dbl>, vessel_id <dbl>, #> #   captain_id <dbl>, duration_min <int>, tow_length_m <dbl>, mouth_width_m <dbl>, ... d |> group_by(ssid, survey_series_desc) |>   mutate(event_skate_id = paste0(fishing_event_id, \"-\", skate_id)) |>   summarise(individuals = sum(catch_count, na.rm = TRUE),             weight = sum(catch_weight),             events = length(unique(fishing_event_id)),             skates = length(unique(event_skate_id)),             rows = n()) |>   arrange(-individuals, -weight) #> # A tibble: 13 x 7 #> # Groups:   ssid [13] #>     ssid survey_series_desc                                   individuals weight events skates  rows #>    <dbl> <chr>                                                      <dbl>  <dbl>  <int>  <int> <int> #>  1    14 \"International Pacific Halibut Commission Fishery-I~         175  NA      3278   3278  3278 #>  2    48 \"Dogfish Gear/Timing Comparison Surveys\"                      38  NA       145    271   271 #>  3    40 \"Hard Bottom Longline Inside South \"                          16  NA       528    528   528 #>  4    76 \"Strait of Georgia Dogfish Longline\"                          13  NA       351    351   351 #>  5    45 \"Strait of Georgia Synoptic Bottom Trawl\"                      2  19.4      98     98    98 #>  6    39 \"Hard Bottom Longline Inside North \"                           1 200       769    769   769 #>  7    34 \"Strait of Georgia Ecosystem Research Initiative Ac~           1  36.7     167    167   167 #>  8     6 \"Queen Charlotte Sound Multispecies Small-mesh Bott~           1   7.14   1295   1295  1295 #>  9    35 \"Sablefish Research and Assessment\"                            1   5.8    3582   3582  3582 #> 10     4 \"West Coast Vancouver Island Synoptic Bottom Trawl\"            1   1.52   1737   1737  1737 #> 11    36 \"Hard Bottom Longline Outside South\"                           1  NA      1536   1536  1536 #> 12     7 \"West Coast Vancouver Island Multispecies Small-mes~           0  15.7    5084   5084  5084 #> 13    80 \"Eulachon Migration Study Bottom Trawl (South)\"                0   4.5     271    271   271 d |> filter(ssid == 14) |>   group_by(major_stat_area_code) |>   summarise(individuals = sum(catch_count, na.rm = TRUE),             weight = sum(catch_weight),             events = length(unique(fishing_event_id))) |>   arrange(-individuals, -weight) #> # A tibble: 8 x 4 #>   major_stat_area_code individuals weight events #>   <chr>                      <dbl>  <dbl>  <int> #> 1 01                           137     NA     43 #> 2 06                            14     NA    831 #> 3 03                            10     NA    383 #> 4 04                            10     NA    262 #> 5 07                             2     NA    757 #> 6 05                             1     NA    362 #> 7 09                             1     NA    201 #> 8 08                             0      0    439"},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"what-survey-samples-are-available-for-a-species-within-a-specific-area","dir":"Articles","previous_headings":"Examples","what":"What survey samples are available for a species within a specific area?","title":"Using 'get_all' functions","text":"example, might want determine survey sample data exists Pacific Spiny Dogfish Strait Georgia. area argument major accepts character vectors major stat area codes. table options can retrieved get_major_area(). return fishery-independent specimen records. haven’t counted actual ages species, none available. get_all_* functions, default drop columns data, case column named age missing. However, column retained using argument drop_na_columns = FALSE. want focus specimens come design-based survey sets can add arguments filter unsorted random samples come events grouping codes match expected current survey design. Alternatively, can achieved filtering specimens !.na(grouping_code) !.na(grouping_code_updated) checking sample_type_comment sample_source_desc notes consistent specimens random samples. , use built filter arguments, also add additional constraint filtering based updated grouping codes. Note: surveys use grouping codes, therefore won’t returned grouping_only option used. case, SSID 51 82:87 now missing. want retrieve additional event skate-level covariates use model-based analyses, use argument include_event_info = TRUE. example, applied various longline surveys Strait Georgia, one can test effects variables like depth, date, hook type size sex sizes fish caught. variables returned default: additional variables returned longline surveys include_event_info = TRUE: collection variables returned can change depending records retrieved. example, variables specific longline surveys omitted trawl survey sets returned.","code":"d2 <- get_all_survey_samples(\"north pacific spiny dogfish\",                              major = c(\"01\")) #> [1] \"Returning all north pacific spiny dogfish specimens from major area(s) 01 from any survey series.\" d2 |> group_by(survey_series_id, survey_series_desc) |>   summarise(specimens = length(unique(specimen_id)),             lengths = sum(!is.na(length)),             weights = sum(!is.na(weight)),             age_structures = sum(age_specimen_collected)             ) |>   arrange(-specimens)|>   rename(ssid = survey_series_id) #> # A tibble: 15 x 6 #> # Groups:   ssid [15] #>     ssid survey_series_desc                                 specimens lengths weights age_structures #>    <dbl> <chr>                                                  <int>   <int>   <int>          <int> #>  1    76 \"Strait of Georgia Dogfish Longline\"                   54716   54690    6582          19053 #>  2    40 \"Hard Bottom Longline Inside South \"                   36566   36561       3              0 #>  3    39 \"Hard Bottom Longline Inside North \"                   35624   35497     408            400 #>  4    48 \"Dogfish Gear/Timing Comparison Surveys\"               16695   16681    3322            884 #>  5    45 \"Strait of Georgia Synoptic Bottom Trawl\"               1721    1721    1243            505 #>  6    15 \"Strait of Georgia Lingcod Young-of-year Bottom T~      1371    1181       0              0 #>  7    34 \"Strait of Georgia Ecosystem Research Initiative ~       925     877     402              0 #>  8    50 \"Yelloweye Rockfish Genetics\"                            786     786       0              0 #>  9    87 \"Jig Survey - 4B Stat Area 19\"                           314     300       0              0 #> 10    86 \"Jig Survey - 4B Stat Area 18\"                           176     164       0              0 #> 11    51 \"Combined Submersible And Longline Fishing Survey\"       169     169     168              0 #> 12    82 \"Jig Survey - 4B Stat Area 12\"                            14      14       0              0 #> 13    85 \"Jig Survey - 4B Stat Area 16\"                             5       4       0              0 #> 14    68 \"Joint Canada/US Hake Acoustic\"                            1       1       1              0 #> 15    84 \"Jig Survey - 4B Stat Area 15\"                             1       0       0              0 d3 <- get_all_survey_samples(\"north pacific spiny dogfish\",                              major = c(\"01\"),                              usability = c(0, 1, 2, 6),                              unsorted_only = TRUE,                              random_only = TRUE,                              grouping_only = TRUE) #> [1] \"Looking for samples that are usable (0, 1, 2, 6) unsorted random with originally specified grouping codes.\" #> [1] \"Returning all north pacific spiny dogfish specimens from major area(s) 01 from any survey series.\" d3 |> filter(!is.na(grouping_code_updated)) |>   group_by(survey_series_id, survey_series_desc) |>   summarise(specimens = length(unique(specimen_id)),             lengths = sum(!is.na(length)),             weights = sum(!is.na(weight)),             age_structures = sum(age_specimen_collected)) |>   arrange(-specimens) |>   rename(ssid = survey_series_id) #> # A tibble: 7 x 6 #> # Groups:   ssid [7] #>    ssid survey_series_desc                                  specimens lengths weights age_structures #>   <dbl> <chr>                                                   <int>   <int>   <int>          <int> #> 1    40 \"Hard Bottom Longline Inside South \"                    35070   35065       3              0 #> 2    39 \"Hard Bottom Longline Inside North \"                    29149   29027     399            400 #> 3    76 \"Strait of Georgia Dogfish Longline\"                    18384   18376       0          15521 #> 4    45 \"Strait of Georgia Synoptic Bottom Trawl\"                1721    1721    1243            505 #> 5    15 \"Strait of Georgia Lingcod Young-of-year Bottom Tr~      1071    1071       0              0 #> 6    34 \"Strait of Georgia Ecosystem Research Initiative A~       215     215       0              0 #> 7    68 \"Joint Canada/US Hake Acoustic\"                             1       1       1              0 d4 <- get_all_survey_samples(\"north pacific spiny dogfish\",                              major = c(\"01\"),                              ssid = c(39, 40, 48, 76),                              include_event_info = TRUE) #> [1] \"Returning all north pacific spiny dogfish specimens from within major area(s) 01 and belonging to survey series 39, 40, 48, 76.\" #> [1] \"Specimens found. Fetching additional event info.\" d4 |> group_by(survey_series_id, activity_desc, hook_desc, hooksize_desc) |>   summarise(specimens = length(unique(specimen_id)),             years = paste(min(year, na.rm = TRUE), \"-\", max(year, na.rm = TRUE))) |>   arrange(-specimens) |>   rename(ssid = survey_series_id, hooksize = hooksize_desc) |>   print() #> # A tibble: 8 x 6 #> # Groups:   ssid, activity_desc, hook_desc [7] #>    ssid activity_desc                                   hook_desc   hooksize specimens years       #>   <dbl> <chr>                                           <chr>       <chr>        <int> <chr>       #> 1    40 HARD BOTTOM LONGLINE HOOK SURVEY - INSIDE SOUTH CIRCLE HOOK 13/0         36566 2005 - 2022 #> 2    76 STRAIT OF GEORGIA DOGFISH LONGLINE SURVEY       CIRCLE HOOK 14/0         36332 2005 - 2019 #> 3    39 HARD BOTTOM LONGLINE HOOK SURVEY - INSIDE NORTH CIRCLE HOOK 13/0         35624 2003 - 2023 #> 4    76 STRAIT OF GEORGIA DOGFISH LONGLINE SURVEY       J-HOOK      12/0         18384 1986 - 1989 #> 5    48 DOGFISH GEAR/TIMING COMPARISON SURVEYS          CIRCLE HOOK 14/0          8474 2004 - 2023 #> 6    48 DOGFISH GEAR/TIMING COMPARISON SURVEYS          CIRCLE HOOK 13/0          7254 2019 - 2023 #> 7    48 DOGFISH GEAR/TIMING COMPARISON SURVEYS          J-HOOK      12/0           948 2004 - 2023 #> 8    48 DOGFISH GEAR/TIMING COMPARISON SURVEYS          <NA>        <NA>            19 2004 - 2004 glimpse(d2) #> Rows: 149,084 #> Columns: 50 #> $ species_common_name          <chr> \"north pacific spiny dogfish\", \"north pacific spiny dogfish\",~ #> $ survey_series_id             <dbl> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1~ #> $ sex                          <dbl> 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2~ #> $ length                       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ weight                       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ survey_series_og             <dbl> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1~ #> $ activity_desc                <chr> \"STRAIT OF GEORGIA LINGCOD YOUNG-OF-YEAR BOTTOM TRAWL SURVEY\"~ #> $ activity_code                <dbl> 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 3~ #> $ fishing_event_id             <dbl> 3132875, 3132875, 3132875, 3132875, 3132875, 3132875, 3132875~ #> $ trip_year                    <int> 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2~ #> $ sample_date                  <dttm> 2006-08-04, 2006-08-04, 2006-08-04, 2006-08-04, 2006-08-04, ~ #> $ species_code                 <chr> \"044\", \"044\", \"044\", \"044\", \"044\", \"044\", \"044\", \"044\", \"044\"~ #> $ species_science_name         <chr> \"squalus suckleyi\", \"squalus suckleyi\", \"squalus suckleyi\", \"~ #> $ specimen_id                  <dbl> 12291537, 12291539, 12291540, 12291542, 12291543, 12291544, 1~ #> $ sample_id                    <dbl> 399729, 399729, 399729, 399729, 399729, 399729, 399729, 39972~ #> $ fork_length                  <dbl> 72, 72, 73, 74, 75, 75, 76, 80, 85, 88, 89, 70, 77, 77, 78, 7~ #> $ total_length                 <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ maturity_code                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~ #> $ maturity_name                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ maturity_desc                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ maturity_convention_code     <dbl> 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9~ #> $ maturity_convention_desc     <chr> \"MATURITIES NOT LOOKED AT\", \"MATURITIES NOT LOOKED AT\", \"MATU~ #> $ maturity_convention_maxvalue <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~ #> $ major_stat_area_code         <chr> \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"~ #> $ major_stat_area_name         <chr> \"4B: STRAIT OF GEORGIA\", \"4B: STRAIT OF GEORGIA\", \"4B: STRAIT~ #> $ minor_stat_area_code         <chr> \"14\", \"14\", \"14\", \"14\", \"14\", \"14\", \"14\", \"14\", \"14\", \"14\", \"~ #> $ gear                         <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ reason_desc                  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ survey_id                    <int> 481, 481, 481, 481, 481, 481, 481, 481, 481, 481, 481, 481, 4~ #> $ trip_id                      <dbl> 73330, 73330, 73330, 73330, 73330, 73330, 73330, 73330, 73330~ #> $ trip_sub_type_code           <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2~ #> $ fe_parent_event_id           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ fe_major_level_id            <dbl> 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4~ #> $ fe_sub_level_id              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ sample_type_code             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ sample_type_comment          <chr> \"TOTAL  CATCH\", \"TOTAL  CATCH\", \"TOTAL  CATCH\", \"TOTAL  CATCH~ #> $ species_category_code        <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ sample_source_code           <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ age_specimen_collected       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~ #> $ usability_code               <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~ #> $ grouping_code                <dbl> 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 1~ #> $ grouping_desc                <chr> \"Lingcod YOY depth stratum 1: 16 - 25 m\", \"Lingcod YOY depth ~ #> $ grouping_code_updated        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ grouping_desc_updated        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ original_ind                 <chr> \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"~ #> $ length_type                  <chr> \"total_length\", \"total_length\", \"total_length\", \"total_length~ #> $ sample_source_desc           <chr> \"Unsorted\", \"Unsorted\", \"Unsorted\", \"Unsorted\", \"Unsorted\", \"~ #> $ usability_desc               <chr> \"FULLY USABLE\", \"FULLY USABLE\", \"FULLY USABLE\", \"FULLY USABLE~ #> $ survey_series_desc           <chr> \"Strait of Georgia Lingcod Young-of-year Bottom Trawl\", \"Stra~ #> $ survey_abbrev                <chr> \"OTHER\", \"OTHER\", \"OTHER\", \"OTHER\", \"OTHER\", \"OTHER\", \"OTHER\"~ glimpse(d4[, !names(d4) %in% names(d2)]) #> Rows: 143,601 #> Columns: 34 #> $ catch_weight         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ catch_count          <dbl> 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 5~ #> $ year                 <int> 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 2023, 202~ #> $ month                <int> 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, ~ #> $ day                  <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ~ #> $ time_deployed        <dttm> 2023-09-02 14:43:16, 2023-09-02 14:43:16, 2023-09-02 14:43:16, 2023-~ #> $ time_retrieved       <dttm> 2023-09-02 16:42:55, 2023-09-02 16:42:55, 2023-09-02 16:42:55, 2023-~ #> $ time_end_deployment  <dttm> 2023-09-02 14:43:16, 2023-09-02 14:43:16, 2023-09-02 14:43:16, 2023-~ #> $ time_begin_retrieval <dttm> 2023-09-02 16:42:55, 2023-09-02 16:42:55, 2023-09-02 16:42:55, 2023-~ #> $ latitude             <dbl> 50.21935, 50.21935, 50.21935, 50.21935, 50.21935, 50.21935, 50.21935,~ #> $ longitude            <dbl> -125.3644, -125.3644, -125.3644, -125.3644, -125.3644, -125.3644, -12~ #> $ latitude_end         <dbl> 50.22198, 50.22198, 50.22198, 50.22198, 50.22198, 50.22198, 50.22198,~ #> $ longitude_end        <dbl> -125.3671, -125.3671, -125.3671, -125.3671, -125.3671, -125.3671, -12~ #> $ depth_m              <dbl> 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 7~ #> $ depth_begin          <dbl> 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 6~ #> $ depth_end            <dbl> 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,~ #> $ vessel_id            <dbl> 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 201~ #> $ captain_id           <dbl> 969, 969, 969, 969, 969, 969, 969, 969, 969, 969, 969, 969, 969, 969,~ #> $ duration_min         <int> 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,~ #> $ tow_length_m         <dbl> 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350, 350,~ #> $ hook_code            <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~ #> $ lglsp_hook_count     <dbl> 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225, 225,~ #> $ hook_desc            <chr> \"CIRCLE HOOK\", \"CIRCLE HOOK\", \"CIRCLE HOOK\", \"CIRCLE HOOK\", \"CIRCLE H~ #> $ hooksize_desc        <chr> \"13/0\", \"13/0\", \"13/0\", \"13/0\", \"13/0\", \"13/0\", \"13/0\", \"13/0\", \"13/0~ #> $ grouping_depth_id    <chr> \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\",~ #> $ grouping_area_km2    <int> 844, 844, 844, 844, 844, 844, 844, 844, 844, 844, 844, 844, 844, 844,~ #> $ skate_count          <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~ #> $ mean_per_skate       <dbl> 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236,~ #> $ minor_id_count       <int> 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236,~ #> $ minor_id_max         <dbl> 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236, 236,~ #> $ diff                 <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~ #> $ event_level_count    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ skate_id             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~ #> $ hook_area_swept_km2  <dbl> 0.005262028, 0.005262028, 0.005262028, 0.005262028, 0.005262028, 0.00~"},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"surveys-with-overlapping-stratifications","dir":"Articles","previous_headings":"Examples","what":"Surveys with overlapping stratifications","title":"Using 'get_all' functions","text":"fishing events assigned multiple surveys, may may fully partially overlapping, defined activity code database. get sets matching activity codes one can use include_activity_matches = TRUE. return events share activity_code SSIDs requested. works retrieving either sets samples. get warning fishing events duplicated even though remove_duplicates = TRUE. can look one duplicated events see lacks location information, means couldn’t accurately assigned either region shrimp survey, returned potentially belonging . NOTE: activity matches always returned default whenever one sablefish surveys (ssid = 35, 41, 42, 43) requested. SSIDs survey inconsistently assigned frequently share trip ids, results duplication assignment wrong survey series. order accurately separate types sablefish surveys one needs split data survey reason_desc variable.","code":"d5 <- get_all_survey_sets(\"north pacific spiny dogfish\",                           ssid = c(7),                           include_activity_matches = TRUE,                           remove_duplicates = TRUE #> default                           ) #> [1] \"north pacific spiny dogfish have been recorded by survey series 7, 6, 67 at least once. \" #> [1] \"Returning all relevant sets/events/skates including those with no catch.\" #> Warning in get_all_survey_sets(\"north pacific spiny dogfish\", ssid = c(7), : Duplicate #> fishing_event_ids are still present despite `remove_duplicates = TRUE`. This may be because of #> overlapping survey stratifications or multiple skates per event (specifically when at least one #> survey included used skates with differences in gear type), but could also be due to trips #> participating in more than one type of survey. If the latter, location, gear, or `reason_desc` #> columns should be used to choose which events to keep. After selecting specific survey #> stratifications and determining that all relevant variables are accurate, the remaining #> duplications can be filtered using `dat <- dat[!duplicated(dat$fishing_event_id), ]`. d5 |> group_by(survey_series_id, survey_abbrev, activity_desc) |>   summarise(events = length(unique(fishing_event_id)),             years = paste(min(year), \"-\", max(year)),             rows = n()) |>   arrange(-events) |>   rename(ssid = survey_series_id) #> # A tibble: 2 x 6 #> # Groups:   ssid, survey_abbrev [2] #>    ssid survey_abbrev activity_desc                                            events years     rows #>   <dbl> <chr>         <chr>                                                     <int> <chr>    <int> #> 1     7 MSSM WCVI     MULTISPECIES SMALL-MESH (AKA SHRIMP) BOTTOM TRAWL SURVEY   5084 1975 - ~  5084 #> 2     6 MSSM QCS      MULTISPECIES SMALL-MESH (AKA SHRIMP) BOTTOM TRAWL SURVEY   1295 1998 - ~  1295 dd <- d5[duplicated(d5$fishing_event_id),] glimpse(dd) #> Rows: 1 #> Columns: 54 #> $ species_common_name   <chr> \"north pacific spiny dogfish\" #> $ catch_count           <dbl> NA #> $ catch_weight          <dbl> 1.9 #> $ survey_series_id      <dbl> 7 #> $ survey_abbrev         <chr> \"MSSM WCVI\" #> $ year                  <int> 2000 #> $ fishing_event_id      <dbl> 901698 #> $ species_code          <chr> \"044\" #> $ fe_major_level_id     <dbl> 9 #> $ trip_id               <dbl> 60021 #> $ survey_series_og      <dbl> 7 #> $ activity_desc         <chr> \"MULTISPECIES SMALL-MESH (AKA SHRIMP) BOTTOM TRAWL SURVEY\" #> $ activity_code         <dbl> 25 #> $ reason_desc           <chr> \"QUANT. BIOMASS SURVEY\" #> $ trip_year             <int> 2000 #> $ month                 <int> NA #> $ day                   <int> NA #> $ time_deployed         <dttm> NA #> $ time_retrieved        <dttm> NA #> $ time_end_deployment   <dttm> NA #> $ time_begin_retrieval  <dttm> NA #> $ latitude              <dbl> NA #> $ longitude             <dbl> NA #> $ latitude_end          <dbl> NA #> $ longitude_end         <dbl> NA #> $ major_stat_area_code  <chr> \"00\" #> $ minor_stat_area_code  <chr> \"00\" #> $ depth_m               <dbl> NA #> $ depth_begin           <dbl> NA #> $ depth_end             <dbl> NA #> $ vessel_id             <dbl> 2000 #> $ captain_id            <dbl> NA #> $ duration_min          <int> NA #> $ tow_length_m          <dbl> NA #> $ mouth_width_m         <dbl> 10.6 #> $ doorspread_m          <dbl> 29.6 #> $ speed_mpm             <dbl> 86.66668 #> $ usability_code        <dbl> 13 #> $ grouping_code         <dbl> NA #> $ grouping_desc         <chr> NA #> $ grouping_code_updated <dbl> NA #> $ grouping_desc_updated <chr> NA #> $ grouping_area_km2     <int> NA #> $ original_ind          <chr> \"Y\" #> $ survey_series_desc    <chr> \"West Coast Vancouver Island Multispecies Small-mesh Bottom Trawl\" #> $ species_science_name  <chr> \"squalus suckleyi\" #> $ species_desc          <chr> \"north pacific spiny dogfish\" #> $ usability_desc        <chr> \"UNUSABLE FOR CPUE ESTIMATION\" #> $ area_swept1           <dbl> NA #> $ area_swept2           <dbl> NA #> $ area_swept            <dbl> NA #> $ area_swept_km2        <dbl> NA #> $ density_kgpm2         <dbl> NA #> $ density_pcpm2         <dbl> NA"},{"path":[]},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"beware-of-duplication-of-fishing-events-and-specimens","dir":"Articles","previous_headings":"Troubleshooting","what":"Beware of duplication of fishing events and specimens","title":"Using 'get_all' functions","text":"risk using get_all_*() functions , attempt return comprehensive data set, fishing events specimen ids may duplicated (also occurs original functions usually different reasons). vessel trips conduct sampling multiple survey series, unless joining based grouping codes (aren’t used consistently surveys) way connect fishing event survey series id vessel trip. can result events specimens getting assigned surveys conducted trip. common instances (e.g., sablefish, jig, offshore shrimp surveys) custom corrections coded internal function correct_ssids() applied within get_all_*() functions. Duplication can also occur due missing covariates (e.g., event level survey defaults missing doorspread_m couple sets trawl survey series), specimens multiple vials DNA collected return_dna_info = TRUE. recommended always check unexpected duplication observations (usually fishing_event_id specimen_id) beginning analysis. Two return copies duplicated record following can used: d[duplicated(d$specimen_id) | duplicated(d$specimen_id, fromLast=TRUE), ].","code":""},{"path":"https://pbs-assess.github.io/gfdata/articles/02-gfdata-vignette-get-all.html","id":"error-messages","dir":"Articles","previous_headings":"Troubleshooting","what":"Error messages","title":"Using 'get_all' functions","text":"error message mentions SQL Server suggests either network connection server timed , SQL query flawed. One way can happen providing invalid ssid (e.g., character “4” instead numeric 4), invalid major area code (e.g., numeric 1 instead character “01”), search insufficiently limited scope. Error: nanodbc/nanodbc.cpp:2823: 08S01 [Microsoft][ODBC SQL Server Driver][DBNETLIB]ConnectionRead (recv()). [Microsoft][ODBC SQL Server Driver][DBNETLIB]General network error. Check network documentation. SQL search successfully returned R, computer insufficient memory handle amount data returned, may see error like : Error: allocate vector size XXX Mb","code":""},{"path":"https://pbs-assess.github.io/gfdata/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Elise . Keppel. Author. Philina . English. Author, maintainer. Sean C. Anderson. Author. Andrew M. Edwards. Author. Chris Grandin. Author.","code":""},{"path":"https://pbs-assess.github.io/gfdata/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Keppel, E.., P.. English, S.C. Anderson, .M. Edwards, C. Grandin. 2024.   gfdata: Data Extraction DFO PBS Groundfish Stocks. R package version   0.1.3. https://github.com/pbs-assess/gfdata Anderson, S.C., E.. Keppel, .M. Edwards. 2019. reproducible data synopsis 100 species British Columbia groundfish. DFO Can. Sci. Advis. Sec. Res. Doc. 2019/041. vii + 321 p.","code":"@Manual{,   title = {{gfdata}: Data Extraction for {DFO} {PBS} Groundfish Stocks},   year = {2024},   note = {R package version 0.1.3},   author = {{Keppel} and E. A. and {English} and P. A. and {Anderson} and {S.C.} and {Edwards} and A. M. and {Grandin} and {C.}},   url = {https://github.com/pbs-assess/gfdata}, } @Article{,   title = {A Reproducible Data Synopsis for over 100 Species of {British Columbia} Groundfish},   author = {{Anderson} and {S.C.} and {Keppel} and E. A. and {Edwards} and A. M.},   year = {2019},   volume = {2019/041},   pages = {vii + 321 p},   journal = {DFO Can. Sci. Advis. Sec. Res. Doc.}, }"},{"path":"https://pbs-assess.github.io/gfdata/index.html","id":"gfdata-an-r-package-for-data-extraction-of-bc-groundfish-data","dir":"","previous_headings":"","what":"Data Extraction for DFO PBS Groundfish","title":"Data Extraction for DFO PBS Groundfish","text":"Installation: Note package useful access PBS network permissions access groundfish databases.","code":"remotes::install_github(\"pbs-assess/gfdata\")"},{"path":"https://pbs-assess.github.io/gfdata/reference/assign_areas.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign areas — assign_areas","title":"Assign areas — assign_areas","text":"Assign areas","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/assign_areas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign areas — assign_areas","text":"","code":"assign_areas(   major_stat_area_description,   area_regex = c(\"3[CD]+\", \"5[AB]+\", \"5[CDE]+\") )"},{"path":"https://pbs-assess.github.io/gfdata/reference/assign_areas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign areas — assign_areas","text":"major_stat_area_description vector major statistical area descriptions. area_regex vector regular expressions describing areas group.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/assign_areas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign areas — assign_areas","text":"","code":"x <- c(   \"5D: NORTHERN HECATE STRAIT\", \"3C: S.W. VANCOUVER ISLAND\",   \"3D: N.W. VANCOUVER ISLAND\" ) assign_areas(x) #> [1] \"5CDE\" \"3CD\"  \"3CD\""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Get all data — get_all_survey_samples","title":"Get all data — get_all_survey_samples","text":"functions get survey set sample data set species major area, activity, specific surveys. main functions package focus retrieving commonly used typs data often limited sets samples conform current design-based standards survey grids. functions retrieve everything therefore require careful consideration data types reasonable include depending purpose. reason function return lot columns, although exact number depends types surveys returned.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get all data — get_all_survey_samples","text":"","code":"get_all_survey_samples(   species,   ssid = NULL,   major = NULL,   usability = NULL,   unsorted_only = FALSE,   random_only = FALSE,   grouping_only = FALSE,   keep_all_ages = FALSE,   include_event_info = FALSE,   include_activity_matches = FALSE,   remove_bad_data = TRUE,   remove_duplicates = TRUE,   return_dna_info = FALSE,   return_specimen_type = FALSE,   drop_na_columns = TRUE,   quiet_option = \"message\" )  get_all_survey_sets(   species,   ssid = NULL,   major = NULL,   years = NULL,   join_sample_ids = FALSE,   remove_false_zeros = TRUE,   remove_bad_data = TRUE,   remove_duplicates = TRUE,   include_activity_matches = FALSE,   usability = NULL,   grouping_only = FALSE,   drop_na_columns = TRUE,   quiet_option = \"message\" )"},{"path":"https://pbs-assess.github.io/gfdata/reference/get_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get all data — get_all_survey_samples","text":"species One species common names (e.g. \"pacific ocean perch\") one species codes (e.g. 396). Species codes can specified numeric vectors c(396, 442) characters c(\"396\", \"442\"). Numeric values shorter 3 digits expanded 3 digits converted character objects (1 turns \"001\"). Species common names species codes mixed. element missing species code, elements assumed species common names. work non-numeric species codes, cases common name needed. ssid numeric vector survey series IDs. Run get_ssids() look-table available survey series IDs surveys series descriptions. Default return data surveys. useful ids include: contemporary trawl (1, 3, 4, 16), historic trawl (2), IPHC (14), sablefish (35), HBLL (22, 36, 39, 40). major Character string (vector) major stat area code(s) include (characters). Use get_major_areas() lookup area codes descriptions. Default NULL. usability vector usability codes include. Defaults NULL, typical set design-based trawl survey index c(0, 1, 2, 6). IPHC codes may different surveys modern Sablefish survey seem assign usabilities. unsorted_only Defaults FALSE, return specimens collected research trips. TRUE returns unsorted (1) NA specimens species_category_code sample_source_code. random_only Defaults FALSE, return specimens collected research trips. TRUE returns randomly sampled specimens (sample_type_code = 1, 2, 6, 7, 8). grouping_only Defaults FALSE, return specimens sets collected research trips. TRUE returns sets specimens fishing events grouping codes match expected survey. Can also achieved filtering specimens !.na(grouping_code). keep_all_ages Defaults FALSE keep ages standard methods surveys NMFS Triennial. include_event_info Logical whether append relevant fishing event info (location, timing, effort, catch, etc.). Defaults TRUE. include_activity_matches Get surveys activity codes match chosen ssids. remove_bad_data Remove known bad data, unrealistic length weight values duplications due trips include multiple surveys. Default TRUE. remove_duplicates Logical whether remove duplicated event records due overlapping survey stratifications original_ind = 'N'. Default FALSE. option remains possible ssids supplied activity matches included. Otherwise turns automatically. return_dna_info DNA container ids sample type returned? can create duplication specimen ids species.  Defaults FALSE. return_specimen_type non-otolith structure types returned? can create duplication specimen ids species.  Defaults FALSE. drop_na_columns Logical removing columns contain NAs. Defaults TRUE. quiet_option Default option, \"message\", suppresses messages sections code lots join_by messages. string allow messages. years Default NULL, returns years. join_sample_ids option problematic, now reverts FALSE. remove_false_zeros Default TRUE make sure weights > 0 associated counts 0 vice versa. Mostly useful trawl data counts taken small catches.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get all data — get_all_survey_samples","text":"","code":"if (FALSE) { # \\dontrun{ ## Import survey catch density and location data by tow or set for plotting ## Specify single or multiple species by common name or species code and ## single or multiple survey series id(s). ## Notes: ## `area_km` is the stratum area used in design-based index calculation. ## `area_swept` is in m^2 and is used to calculate density for trawl surveys ## It is based on `area_swept1` (`doorspread_m` x `tow_length_m`) except ## when `tow_length_m` is missing, and then we use `area_swept2` ## (`doorspread` x `duration_min` x `speed_mpm`). ## `duration_min` is derived in the SQL procedure \"proc_catmat_2011\" and ## differs slightly from the difference between `time_deployed` and ## `time_retrieved`. } # }"},{"path":"https://pbs-assess.github.io/gfdata/reference/get_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get PBS data — get_data","title":"Get PBS data — get_data","text":"Automates fisheries research survey data extraction DFO Pacific groundfish databases. output datasets feed functions (tidy_, plot_, fit_ functions) data visualization, can used products can fed automated DFO Pacific groundfish data synopsis report production.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get PBS data — get_data","text":"","code":"get_survey_sets(   species,   ssid = c(1, 3, 4, 16, 2, 14, 22, 36, 39, 40),   join_sample_ids = FALSE,   verbose = FALSE,   sleep = 0.05 )  get_ll_hook_data(species = NULL, ssid = NULL)  get_survey_samples(   species,   ssid = NULL,   remove_bad_data = TRUE,   unsorted_only = TRUE,   usability = NULL,   major = NULL )  get_commercial_samples(   species,   unsorted_only = TRUE,   return_all_lengths = FALSE,   major = NULL,   usability = NULL )  get_catch(species, major = NULL)  get_cpue_historical(   species = NULL,   major = NULL,   alt_year_start_date = \"04-01\",   areas = c(\"3[CD]+\", \"5[AB]+\", \"5[CDE]+\"),   end_year = NULL )  get_cpue_historical_hake(end_year = NULL)  get_cpue_historical_hl(   species = NULL,   major = NULL,   alt_year_start_date = \"04-01\",   areas = c(\"3[CD]+\", \"5[AB]+\", \"5[CDE]+\"),   end_year = NULL )  get_cpue_spatial(species, major = NULL)  get_catch_spatial(species, major = NULL)  get_cpue_spatial_ll(species, major = NULL)  get_cpue_index(gear = \"bottom trawl\", min_cpue_year = 1996, major = NULL)  get_cpue_index_hl(min_cpue_year = 1980, major = NULL)  get_age_precision(species, major = NULL)  get_survey_index(species, ssid = NULL)  get_sable_landings(species, ssid = NULL)  get_survey_blocks(ssid = NULL)  get_eulachon_specimens()  get_gear_types()  get_management(   species = NULL,   species_group = NULL,   fishery = NULL,   area = NULL,   start_year = NULL )  cache_pbs_data(   species,   major = NULL,   file_name = NULL,   path = \".\",   compress = FALSE,   unsorted_only = TRUE,   historical_cpue = FALSE,   survey_sets = FALSE,   verbose = TRUE,   return_all_lengths = FALSE )  get_hake_survey_samples()  get_hake_catch(end_date = format(Sys.Date(), \"%d/%m/%Y\"))  get_sablefish_surveys()"},{"path":"https://pbs-assess.github.io/gfdata/reference/get_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get PBS data — get_data","text":"species One species common names (e.g. \"pacific ocean perch\") one species codes (e.g. 396). Species codes can specified numeric vectors c(396, 442) characters c(\"396\", \"442\"). Numeric values shorter 3 digits expanded 3 digits converted character objects (1 turns \"001\"). Species common names species codes mixed. element missing species code, elements assumed species common names. ssid numeric vector survey series IDs. Run get_ssids() look-table available survey series IDs surveys series descriptions. join_sample_ids TRUE sample IDs joined . may result repeated rows data sample ID part different survey stratifications. verbose TRUE extra messages reprinted data extraction. Useful monitor progress. sleep System sleep seconds survey-year kind server. remove_bad_data Remove known bad data, unrealistic length weight values. unsorted_only Remove sorted biological data ('keepers' 'discards' unknown). Default = TRUE. usability vector usability codes include. Defaults . IPHC codes may different surveys. major select inside population (Strait Georgia, area 4B ), set inside = 1. select outside population, set inside = 0. return_all_lengths Include length types, rather just common measurement. Default = FALSE. alt_year_start_date Alternative year starting date specified month-day combination. E.g. \"03-01\" March 1st. Can used create 'fishing years'. areas Area groupings vector regular expressions. See base::regex(). end_year Specify last calendar year extracted. gear gear type(s) include CPUE. converted uppercase. Run get_comm_gear_types() look-table available gear types select . min_cpue_year Minimum year CPUE data. species_group Species group code(s) include (see lookup table get_species_groups()). Defaults . fishery fishery_id code(s) (see lookup table get_fishery_ids()) fisheries include data extraction. Defaults . area fishery area(s) (see lookup table get_management_areas()) include data extraction (eg. '5A'; c('3C', '3D', '5A', '5B')). start_year minimum year include management actions. Defaults . file_name Optional filename(s) cached file. Defaults species argument. path folder cached data saved. compress Compress .rds file? Defaults FALSE faster reading writing expense disk space. historical_cpue Logical whether historical CPUE included. survey_sets Logical whether survey set data extracted. might set FALSE need data want substantially speed data extraction. end_date string representing date. Must format dd/mm/yyyy","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get PBS data — get_data","text":"get_* functions return data frame. cache_pbs_data() function writes .rds file path specified species. data object single species named list object element containing data frame get_* function. element name list reflects function name get_ part removed. example, output get_survey_samples() list element named survey_samples().","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get PBS data — get_data","text":"get_survey_sets() extracts survey catch data spatial data plotting survey catchs map British Columbia get_survey_samples() extracts biological sample specimen records research surveys given species survey series IDs GFBio get_hake_survey_samples() extracts biological sample specimen records hake joint acoustic surveys GFBio get_commercial_samples() extracts biological sample specimen records commercial data given species GFBio get_catch() extracts landing discard records given species GFFOS.GF_MERGED_CATCH get_hake_catch() extracts landing discard records Pacific Hake extra data used Hake assessment get_cpue_spatial() extracts catch, effort spatial data GFFOS.GF_D_OFFICIAL_CATCH groundfish trawl fishery get_cpue_spatial_ll() extracts catch, effort spatial data GFFOS.GF_D_OFFICIAL_CATCH longline fishery get_cpue_index() extracts catch effort data GFFOS.GF_MERGED_CATCH groundfish trawl fishery since 1996 get_cpue_historical() extracts historical catch effort data back 1950s. help file separate page; see link get_age_precision() extracts age readings biological samples given species second ('precision') age reading get_sara_dat() scrubs Species Risk website --date species status listings get_survey_index() extracts survey catch data given species survey series IDs get_management() extracts management actions cache_pbs_data() runs 'get' functions gfdata package (except specific IPHC data) caches extracted data given folder cache_pbs_data() function caches data get_survey_samples() get_commercial_samples() get_catch() get_cpue_spatial() get_cpue_spatial_ll() get_catch_spatial() get_survey_index() get_age_precision() optionally get_survey_sets() get_cpue_historical()","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_data.html","id":"authentication","dir":"Reference","previous_headings":"","what":"Authentication","title":"Get PBS data — get_data","text":"get_* functions extract data performed computer connected Pacific Biological Station DFO network. default, functions assume authorized DFO Windows computer authentication databases happens automatically. instead, wish connect username password, see details section run_sql().","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get PBS data — get_data","text":"","code":"if (FALSE) { # \\dontrun{ ## Import survey catch density and location data by tow or set for plotting ## Specify single or multiple species by common name or species code and ## single or multiple survey series id(s). get_survey_sets(species = \"lingcod\", ssid = 1)  ## Import survey or commercial biological data for various plots ## (e.g. length frequency, growth, age frequency, maturity, etc.) get_survey_samples(species = 442, ssid = c(1, 3, 4, 16))  get_commercial_samples(c(442, 397))  ## Import catch data by species for barcharts of landings by fishing area, ## geartype, and year. get_catch(\"lingcod\")  ## Import spatial commercial catch per unit effort data for trawl or longline ## data by species for plotting along BC coast. get_cpue_spatial(\"lingcod\") get_cpue_spatial_ll(\"yelloweye rockfish\")  ## Import catch and effort data by gear type for modelling commercial trawl ## cpue index. get_cpue_index(gear = \"bottom trawl\", min_cpue_year = 2012)  ## Import survey bootstrapped biomass estimates for plotting relative biomass ## indices by specified survey series. get_survey_index(\"pacific cod\", ssid = c(1, 3, 4, 16)) } # }"},{"path":"https://pbs-assess.github.io/gfdata/reference/get_environmental_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Environmental data extraction functions from surveys — get_sensor_data_trawl","title":"Environmental data extraction functions from surveys — get_sensor_data_trawl","text":"Environmental data extraction functions surveys. See Details section.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_environmental_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Environmental data extraction functions from surveys — get_sensor_data_trawl","text":"","code":"get_sensor_data_trawl(   ssid = NULL,   attribute = c(\"temperature\", \"depth\", \"dissolved oxygen\", \"salinity\"),   spread_attributes = FALSE )  get_sensor_data_trawl_fe(   fishing_event_id = NULL,   attribute = c(\"temperature\", \"depth\", \"dissolved oxygen\", \"salinity\"),   sensor_name = NULL )  get_sensor_data_ll_td(   ssid = NULL,   attribute = c(\"temperature\", \"depth\"),   spread_attributes = FALSE )  get_sensor_data_ll_td_fe(   fishing_event_id = NULL,   attribute = c(\"temperature\", \"depth\") )  get_sensor_data_ll_ctd(   ssid = NULL,   attribute = c(\"temperature\", \"depth\", \"dissolved oxygen\", \"salinity\"),   spread_attributes = FALSE )  get_sensor_data_ll_ctd_fe(   fishing_event_id = NULL,   attribute = c(\"temperature\", \"depth\", \"dissolved oxygen\", \"salinity\") )"},{"path":"https://pbs-assess.github.io/gfdata/reference/get_environmental_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Environmental data extraction functions from surveys — get_sensor_data_trawl","text":"ssid numeric vector survey series IDs. Run get_ssids() look-table available survey series IDs surveys series descriptions. attribute character vector sensor attributes filter . Run get_sensor_attributes() look-table available attributes. spread_attributes Logical whether attributes returned wider format. Allows user choose whether data output wide format (TRUE``) min max values attribute fishing event, long format (FALSE“) mean values attribute fishing event. fishing_event_id vector fishing events filter sensor_name character vector sensor names filter .","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_environmental_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Environmental data extraction functions from surveys — get_sensor_data_trawl","text":"get_sensor_data_trawl(): Environmental data extraction sensors deployed trawl survey gear get_sensor_data_trawl_fe(): Environmental data extraction trawl surveys, individual fishing events. get_sensor_data_ll_td(): Environmental data extraction sensors deployed longline survey gear. get_sensor_data_ll_td_fe(): Environmental data extraction sensors deployed longline survey gear individual fishing events. get_sensor_data_ll_ctd(): Environmental data extraction ctd's deployed longline surveys. Ctd deployments tied directly longline survey fishing event id's. unique fishing event id's deployments can linked longline survey data joining block designation (site number). get_sensor_data_ll_ctd_fe(): Envirnmental data extraction (ctd data) near longline survey sites individual fishing events.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_environmental_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Environmental data extraction functions from surveys — get_sensor_data_trawl","text":"","code":"if (FALSE) { # \\dontrun{ d <- get_sensor_data_trawl(ssid = 1, \"temperature\") head(d) head(get_sensor_data_trawl_fe(d$fishing_event_id[[1]], \"temperature\"))  d <- get_sensor_data_ll_td(ssid = 40) head(d) head(get_sensor_data_ll_td_fe(d$fishing_event_id[[1]],\"temperature\"))  d <- get_sensor_data_ll_ctd(40) head(d) } # }"},{"path":"https://pbs-assess.github.io/gfdata/reference/get_stomach.html","id":null,"dir":"Reference","previous_headings":"","what":"Get stomach contents — get_survey_stomachs","title":"Get stomach contents — get_survey_stomachs","text":"Get stomach contents","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/get_stomach.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get stomach contents — get_survey_stomachs","text":"","code":"get_survey_stomachs(   ssid = NULL,   unsorted_only = FALSE,   usability = NULL,   major = NULL )  get_all_stomachs(unsorted_only = FALSE, major = NULL, usability = NULL)"},{"path":"https://pbs-assess.github.io/gfdata/reference/get_stomach.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get stomach contents — get_survey_stomachs","text":"ssid numeric vector survey series IDs. Run get_ssids() look-table available survey series IDs surveys series descriptions. unsorted_only Remove sorted biological data ('keepers' 'discards' unknown). Default = FALSE. IPHC codes may different surveys. usability vector usability codes include. Defaults . major Character string (vector, though work yet cache_pbs_data) major stat area code include (characters). Use get_major_areas() lookup area codes descriptions.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/gfdata-package.html","id":null,"dir":"Reference","previous_headings":"","what":"gfdata: Data Extraction for DFO PBS Groundfish Stocks — gfdata-package","title":"gfdata: Data Extraction for DFO PBS Groundfish Stocks — gfdata-package","text":"Facilitates groundfish data extraction Canadian Department Fisheries Oceans (DFO) Pacific Biological Station (PBS).","code":""},{"path":[]},{"path":"https://pbs-assess.github.io/gfdata/reference/gfdata-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"gfdata: Data Extraction for DFO PBS Groundfish Stocks — gfdata-package","text":"Maintainer: Philina . English philina.english@dfo-mpo.gc.ca Authors: Elise . Keppel Sean C. Anderson sean.anderson@dfo-mpo.gc.ca Andrew M. Edwards Chris Grandin","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/inject_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"gfdata utilities — inject_filter","title":"gfdata utilities — inject_filter","text":"gfdata utilities","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/inject_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gfdata utilities — inject_filter","text":"","code":"inject_filter(   sql_precode,   species,   sql_code,   search_flag = \"-- insert species here\",   conversion_func = common2codes )"},{"path":"https://pbs-assess.github.io/gfdata/reference/inject_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"gfdata utilities — inject_filter","text":"sql_precode SQL go inject species list etc. species vector species similar objects. sql_code SQL go operate . search_flag search terms inject code. conversion_func conversion function apply species related vector.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/iphc.html","id":null,"dir":"Reference","previous_headings":"","what":"IPHC data cleaned for use for non-halibut index standardization at PBS — iphc_sets","title":"IPHC data cleaned for use for non-halibut index standardization at PBS — iphc_sets","text":"data best used spatiotemporal analyses. Also see gfiphc package implements design-based index standardization. Data 1998 onwards come IPHC website. Data 1996 1997 come local spreadsheets described gfiphc.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/iphc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IPHC data cleaned for use for non-halibut index standardization at PBS — iphc_sets","text":"","code":"iphc_sets  iphc_catch"},{"path":"https://pbs-assess.github.io/gfdata/reference/iphc.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"IPHC data cleaned for use for non-halibut index standardization at PBS — iphc_sets","text":"2 data frames joined, data frame columns: year Year station Station ID station_key unique station key IPHC; occasionally multiple sets station column always unique. also unique across years. longitude Longitude (mid point) latitude Latitude (mid point) species_science_name Scientific name hooks_observed Number hooks observed non-halibut species number_observed Number hooks species interest pbs_standard_grid Logical: standard grid stations time defined gfiphc inside_wcvi Logical: inside Vancouver Island waters (2018 ) vs. anywhere else; may want exclude spatiotemporal modelling sample_type Sample type (first 20 hooks vs. hooks) soak_time_min Soak time temp_c Temperature degrees C depth_m Depth m species_common_name Species common name object class tbl_df (inherits tbl, data.frame) 306480 rows 6 columns.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/iphc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"IPHC data cleaned for use for non-halibut index standardization at PBS — iphc_sets","text":"One likely wants join data frames. E.g.","code":"iphc <- dplyr::inner_join(iphc_catch, iphc_sets)"},{"path":"https://pbs-assess.github.io/gfdata/reference/load_iphc_dat.html","id":null,"dir":"Reference","previous_headings":"","what":"Load and join IPHC FISS set and catch data — load_iphc_dat","title":"Load and join IPHC FISS set and catch data — load_iphc_dat","text":"data start year 1996.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/load_iphc_dat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load and join IPHC FISS set and catch data — load_iphc_dat","text":"","code":"load_iphc_dat(species = NULL)"},{"path":"https://pbs-assess.github.io/gfdata/reference/load_iphc_dat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load and join IPHC FISS set and catch data — load_iphc_dat","text":"species Optional vector specifying species_common_name subset IPHC data.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/load_iphc_dat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load and join IPHC FISS set and catch data — load_iphc_dat","text":"tibble 273,714 rows 22 columns, containing processed IPHC catch set data. main columns include: year. Year set hauled. station. Permanent station ID named IPHC. station_key. Unique key set; can used join set table non-Pacific halibut catch data FISS Survey download page. Occasionally multiple sets station column always unique. also unique across years. species_common_name. Species name used GFBio. species_science_name. Scientific name used GFBio. number_observed. Number hooks species interest. species skates shortspine thornyheads enumerated species level early years values NA. longitude. Longitude decimal degrees midpoint set. latitude. Latitude decimal degrees midpoint set. usable. IPHC indication whether station deemed effective (\"Y\") ineffective (\"N\") assessment. hooks_retrieved. Number hooks retrieved. hooks_observed. Number hooks observed non-Pacific halibut species catch. Pacific halibut value hooks_retrieved. pbs_standard_grid. Stations defined 'standard' gfiphc. inside_wcvi. Logical: inside Vancouver Island waters (2018 ) vs. anywhere else; may want exclude spatiotemporal modelling. sample_type. Type observations. \"20 hooks\" - Observation first 20 (non-halibut) hooks skate. \"hooks\" - hooks observed. depth_m. Average beginning end depth set metres. temp_c. Temperature profiler max pressure (degrees Celsius). soak_time_min. Time interval gear water (minutes). avg_no_hook_per_skate. Average number hooks per skate setting. no_skates_hauled. Number skates hauled (metadata IPHC website). no_skates_set. Number skates set, adjusted baits average number hooks per skate. effective_skates. hooks observed, effective skate number found raw IPHC FISS set data. 1995-1997 value comes gfiphc. cases subset hooks observed, effective skate based observed hooks scaled : effective_skates * (hooks_observed / hooks_retrieved). See eqn G.4 Anderson et al. (2019). baits_returned. number baited hooks remaining. unavailable (NA) Pacific halibut records sample_type = '20 hooks'. tibble also contains following attributes: iphc_download_date. Date data downloaded, e.g., \"2024-05-23\". data_preparation_date. Date  data prepared, e.g., \"2024-06-11\".","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/load_iphc_dat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load and join IPHC FISS set and catch data — load_iphc_dat","text":"function joins IPHC catch data set metadata. needed Pacific halibut enumerated hooks_retrieved year non-halibut species enumerated hooks_observed year. catch set dataframes saved separately space efficiency. Note 2012 bait experiment run typically used chum bait used 4 skates (see Appendix G.3 Anderson et al. 2019 Henry et al. 2013). Therefore estimated hooks_observed Pacific halibut 2012 avg_no_hook_per_skate * .data$no_skates_hauled IPHC effective_skates = 0, returned NA. total estimate hooks observed Pacific halibut therefore baits, chum-.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/load_iphc_dat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Load and join IPHC FISS set and catch data — load_iphc_dat","text":"Anderson, S.C., E.. Keppel, .M. Edwards. 2019. reproducible data synopsis 100 species British Columbia groundfish. DFO Can. Sci. Advis. Sec. Res. Doc. 2019/041. vii + 321 p. Henry, E., Soderlund, E., Dykstra, C.L., Geernaert, T.O., Ranta, .M. 2013. 2012 standardized stock assessment survey. Int. Pac. Halibut Comm. Report Assessment Research Activities 2012. pp. 503–538.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/load_iphc_dat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load and join IPHC FISS set and catch data — load_iphc_dat","text":"","code":"if (FALSE) { # \\dontrun{ # Retrieve and process the IPHC data iphc_data <- load_iphc_dat() } # }"},{"path":"https://pbs-assess.github.io/gfdata/reference/lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"Lookup PBS metadata and descriptive data filters — lookup","title":"Lookup PBS metadata and descriptive data filters — lookup","text":"Extracts metadata descriptive details useful filtering data (.e. extracting data specific survey). Codes often used arguments filtering can looked functions.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lookup PBS metadata and descriptive data filters — lookup","text":"","code":"get_ssids()  get_active_survey_blocks(ssid = NULL, active_only = TRUE)  get_major_areas()  get_management_areas()  get_fishery_ids()  get_species_groups()  get_comm_gear_types()  get_survey_gear_types()  get_age_methods()  get_species()  get_strata_areas()  get_survey_ids(ssid)  get_sensor_attributes()  get_fishery_sectors()  get_other_surveys()  get_table(name)"},{"path":"https://pbs-assess.github.io/gfdata/reference/lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lookup PBS metadata and descriptive data filters — lookup","text":"ssid numeric vector survey series IDs. Run get_ssids() look-table available survey series IDs surveys series descriptions. active_only Logical: return active blocks? name name table get records . code table use variable name without '_code' suffix.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/lookup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lookup PBS metadata and descriptive data filters — lookup","text":"get_ssids() produces lookup table survey series IDs descriptions get_age_methods() produces lookup table ageing method codes descriptions get_sample_trips()produces lookup table sample ID fishing event ID get_strata_areas() produces lookup table surveyed area stratum within surveys get_survey_ids() produces lookup table survey IDs given survey series ID get_major_areas() produces lookup table major area descriptions given major area code","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/mssm_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Multispecies Small-Mesh Bottom Trawl (MSSM) Survey Grid — mssm_grid","title":"Multispecies Small-Mesh Bottom Trawl (MSSM) Survey Grid — mssm_grid","text":"3x3 km grid Multispecies Small-Mesh Bottom Trawl Survey (MSSM; formerly known 'shrimp survey'). grid covers WCVI Shrimp Survey Areas 124 125. year last year grid cell sampled 2023, consistent resampling (spatially) occurring grid cells last sampled 2009 2021.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/mssm_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multispecies Small-Mesh Bottom Trawl (MSSM) Survey Grid — mssm_grid","text":"","code":"mssm_grid  mssm_grid_sf"},{"path":"https://pbs-assess.github.io/gfdata/reference/mssm_grid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Multispecies Small-Mesh Bottom Trawl (MSSM) Survey Grid — mssm_grid","text":"object class sf (inherits tbl_df, tbl, data.frame) 3735 rows 3 columns.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/mssm_grid.html","id":"mssm-grid","dir":"Reference","previous_headings":"","what":"mssm_grid","title":"Multispecies Small-Mesh Bottom Trawl (MSSM) Survey Grid — mssm_grid","text":"data frame 3,735 rows 5 columns: survey_abbrev Survey abbreviation longitude, latitude Longitude latitude centroid 3x3 km grid cells area Area grid cells, km^2 year year grid cell sampled. grid cell can multiple year values","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/mssm_grid.html","id":"mssm-grid-sf","dir":"Reference","previous_headings":"","what":"mssm_grid_sf","title":"Multispecies Small-Mesh Bottom Trawl (MSSM) Survey Grid — mssm_grid","text":"simple features (sf object) version mssm_grid","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/run_sql.html","id":null,"dir":"Reference","previous_headings":"","what":"Run SQL — run_sql","title":"Run SQL — run_sql","text":"Run SQL","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/run_sql.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run SQL — run_sql","text":"","code":"run_sql(database, query)"},{"path":"https://pbs-assess.github.io/gfdata/reference/run_sql.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run SQL — run_sql","text":"database name database. query query run.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/run_sql.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run SQL — run_sql","text":"need use user-password setup access databases, need set R options .Rprofile file: pbs.uid, pbs.pwd, pbs.ip, pbs.sqldriver. E.g. options(pbs.uid=\"MyUserName\") default SQL driver \"SQL Server\" specified options. probably work people. might try using usethis::edit_r_profile() need help finding R profile file.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/run_sql.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run SQL — run_sql","text":"","code":"if (FALSE) { # \\dontrun{ run_sql(\"GFBioSQL\", \"EXEC sp_who2\") } # }"},{"path":"https://pbs-assess.github.io/gfdata/reference/survey_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Active survey blocks — survey_blocks","title":"Active survey blocks — survey_blocks","text":"Active survey blocks DFO Pacific groundfish surveys. Obtained via gfdata::get_active_survey_blocks() cleaning documented data-raw/survey_blocks.R.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/survey_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Active survey blocks — survey_blocks","text":"","code":"survey_blocks"},{"path":"https://pbs-assess.github.io/gfdata/reference/survey_blocks.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Active survey blocks — survey_blocks","text":"Simple feature (sf) collection 66293 features 6 fields: survey_abbrev Survey abbreviation. survey_series_id Unique identifier survey series. station_key Unique identifier grid cell depth_m Depth metres. active_block block actively fished date downloaded: e.g., attr(gfdata::survey_blocks, \"date-downloaded\")) geometry Represents grid cell. area Overwater area km^2.","code":""},{"path":"https://pbs-assess.github.io/gfdata/reference/survey_blocks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Active survey blocks — survey_blocks","text":"","code":"requireNamespace(\"ggplot2\", quietly = TRUE) library(sf) #> Linking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.4.0; sf_use_s2() is TRUE library(ggplot2) gfdata::survey_blocks |>   filter(active_block) |>   ggplot(aes(colour = survey_abbrev)) +   geom_sf() +   theme_minimal() +   scale_colour_brewer(palette = \"Dark2\") #> Error: object 'active_block' not found attr(gfdata::survey_blocks, \"date-generated\") #> [1] \"2024-06-26\" attr(gfdata::survey_blocks, \"date-downloaded\") #> [1] \"2024-06-13\""}]
